<!--
This HTML is auto-generated.  DO NOT EDIT THIS FILE!  If you are writing a new
PEP, see http://www.python.org/dev/peps/pep-0001 for instructions and links
to templates.  DO NOT USE THIS HTML FILE AS YOUR TEMPLATE!
-->
<table class="rfc2822 docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">PEP:</th><td class="field-body">533</td>
</tr>
<tr class="field"><th class="field-name">Title:</th><td class="field-body">Deterministic cleanup for iterators</td>
</tr>
<tr class="field"><th class="field-name">Version:</th><td class="field-body">$Revision$</td>
</tr>
<tr class="field"><th class="field-name">Last-Modified:</th><td class="field-body"><a class="reference external" href="https://hg.python.org/peps/file/tip/pep-0533.txt">$Date$</a></td>
</tr>
<tr class="field"><th class="field-name">Author:</th><td class="field-body">Nathaniel J. Smith</td>
</tr>
<tr class="field"><th class="field-name">Status:</th><td class="field-body">Draft</td>
</tr>
<tr class="field"><th class="field-name">Type:</th><td class="field-body">Standards Track</td>
</tr>
<tr class="field"><th class="field-name">Content-Type:</th><td class="field-body"><a class="reference external" href="/dev/peps/pep-0012">text/x-rst</a></td>
</tr>
<tr class="field"><th class="field-name">Created:</th><td class="field-body">18-Oct-2016</td>
</tr>
<tr class="field"><th class="field-name">Post-History:</th><td class="field-body">18-Oct-2016</td>
</tr>
</tbody>
</table>
<hr />
<div class="contents topic" id="contents">
<p class="topic-title first">Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#abstract" id="id2">Abstract</a></li>
<li><a class="reference internal" href="#note-on-timing" id="id3">Note on timing</a></li>
<li><a class="reference internal" href="#background-and-motivation" id="id4">Background and motivation</a></li>
<li><a class="reference internal" href="#alternatives" id="id5">Alternatives</a><ul>
<li><a class="reference internal" href="#pep-525-asyncgen-hooks" id="id6">PEP 525 asyncgen hooks</a></li>
<li><a class="reference internal" href="#always-inject-resources-and-do-all-cleanup-at-the-top-level" id="id7">Always inject resources, and do all cleanup at the top level</a></li>
<li><a class="reference internal" href="#more-complex-variants-of-a-iterclose" id="id8">More complex variants of __(a)iterclose__</a></li>
</ul>
</li>
<li><a class="reference internal" href="#specification" id="id9">Specification</a><ul>
<li><a class="reference internal" href="#guiding-principles" id="id10">Guiding principles</a></li>
<li><a class="reference internal" href="#changes-to-iteration" id="id11">Changes to iteration</a></li>
<li><a class="reference internal" href="#changes-to-async-iteration" id="id12">Changes to async iteration</a></li>
<li><a class="reference internal" href="#modifications-to-basic-iterator-types" id="id13">Modifications to basic iterator types</a></li>
<li><a class="reference internal" href="#new-convenience-functions" id="id14">New convenience functions</a></li>
<li><a class="reference internal" href="#iterclose-implementations-for-iterator-wrappers" id="id15">__iterclose__ implementations for iterator wrappers</a></li>
<li><a class="reference internal" href="#example-rationale" id="id16">Example / Rationale</a></li>
</ul>
</li>
<li><a class="reference internal" href="#transition-plan" id="id17">Transition plan</a></li>
<li><a class="reference internal" href="#acknowledgements" id="id18">Acknowledgements</a></li>
<li><a class="reference internal" href="#copyright" id="id19">Copyright</a></li>
</ul>
</div>
<div class="section" id="abstract">
<h1><a class="toc-backref" href="#id2">Abstract</a></h1>
<p>We propose to extend the iterator protocol with a new
<tt class="docutils literal">__(a)iterclose__</tt> slot, which is called automatically on exit from
<tt class="docutils literal">(async) for</tt> loops, regardless of how they exit. This allows for
convenient, deterministic cleanup of resources held by iterators
without reliance on the garbage collector. This is especially valuable
for asynchronous generators.</p>
</div>
<div class="section" id="note-on-timing">
<h1><a class="toc-backref" href="#id3">Note on timing</a></h1>
<p>In practical terms, the proposal here is divided into two separate
parts: the handling of async iterators, which should ideally be
implemented ASAP, and the handling of regular iterators, which is a
larger but more relaxed project that can't start until 3.7 at the
earliest. But since the changes are closely related, and we probably
don't want to end up with async iterators and regular iterators
diverging in the long run, it seems useful to look at them together.</p>
</div>
<div class="section" id="background-and-motivation">
<h1><a class="toc-backref" href="#id4">Background and motivation</a></h1>
<p>Python iterables often hold resources which require cleanup. For
example: <tt class="docutils literal">file</tt> objects need to be closed; the <a class="reference external" href="https://www.python.org/dev/peps/pep-0333/">WSGI spec</a> adds a <tt class="docutils literal">close</tt> method
on top of the regular iterator protocol and demands that consumers
call it at the appropriate time (though forgetting to do so is a
<a class="reference external" href="http://blog.dscpl.com.au/2012/10/obligations-for-calling-close-on.html">frequent source of bugs</a>);
and <a class="reference external" href="/dev/peps/pep-0342">PEP 342</a> (based on <a class="reference external" href="/dev/peps/pep-0325">PEP 325</a>) extended generator objects to add a
<tt class="docutils literal">close</tt> method to allow generators to clean up after themselves.</p>
<p>Generally, objects that need to clean up after themselves also define
a <tt class="docutils literal">__del__</tt> method to ensure that this cleanup will happen
eventually, when the object is garbage collected. However, relying on
the garbage collector for cleanup like this causes serious problems in
several cases:</p>
<ul class="simple">
<li>In Python implementations that do not use reference counting
(e.g. PyPy, Jython), calls to <tt class="docutils literal">__del__</tt> may be arbitrarily delayed
-- yet many situations require <em>prompt</em> cleanup of
resources. Delayed cleanup produces problems like crashes due to
file descriptor exhaustion, or WSGI timing middleware that collects
bogus times.</li>
<li>Async generators (<a class="reference external" href="/dev/peps/pep-0525">PEP 525</a>) can only perform cleanup under the
supervision of the appropriate coroutine runner. <tt class="docutils literal">__del__</tt> doesn't
have access to the coroutine runner; indeed, the coroutine runner
might be garbage collected before the generator object. So relying
on the garbage collector is effectively impossible without some kind
of language extension. (<a class="reference external" href="/dev/peps/pep-0525">PEP 525</a> does provide such an extension, but
it has a number of limitations that this proposal fixes; see the
&quot;alternatives&quot; section below for discussion.)</li>
</ul>
<!-- XX add discussion of:

- Causality preservation, context preservation

- Exception swallowing -->
<p>Fortunately, Python provides a standard tool for doing resource
cleanup in a more structured way: <tt class="docutils literal">with</tt> blocks. For example, this
code opens a file but relies on the garbage collector to close it:</p>
<pre class="literal-block">
def read_newline_separated_json(path):
    for line in open(path):
        yield json.loads(line)

for document in read_newline_separated_json(path):
    ...
</pre>
<p>and recent versions of CPython will point this out by issuing a
<tt class="docutils literal">ResourceWarning</tt>, nudging us to fix it by adding a <tt class="docutils literal">with</tt> block:</p>
<pre class="literal-block">
def read_newline_separated_json(path):
    with open(path) as file_handle:      # &lt;-- with block
        for line in file_handle:
            yield json.loads(line)

for document in read_newline_separated_json(path):  # &lt;-- outer for loop
    ...
</pre>
<p>But there's a subtlety here, caused by the interaction of <tt class="docutils literal">with</tt>
blocks and generators. <tt class="docutils literal">with</tt> blocks are Python's main tool for
managing cleanup, and they're a powerful one, because they pin the
lifetime of a resource to the lifetime of a stack frame. But this
assumes that someone will take care of cleaning up the stack
frame... and for generators, this requires that someone <tt class="docutils literal">close</tt>
them.</p>
<p>In this case, adding the <tt class="docutils literal">with</tt> block <em>is</em> enough to shut up the
<tt class="docutils literal">ResourceWarning</tt>, but this is misleading -- the file object cleanup
here is still dependent on the garbage collector. The <tt class="docutils literal">with</tt> block
will only be unwound when the <tt class="docutils literal">read_newline_separated_json</tt>
generator is closed. If the outer <tt class="docutils literal">for</tt> loop runs to completion then
the cleanup will happen immediately; but if this loop is terminated
early by a <tt class="docutils literal">break</tt> or an exception, then the <tt class="docutils literal">with</tt> block won't
fire until the generator object is garbage collected.</p>
<p>The correct solution requires that all <em>users</em> of this API wrap every
<tt class="docutils literal">for</tt> loop in its own <tt class="docutils literal">with</tt> block:</p>
<pre class="literal-block">
with closing(read_newline_separated_json(path)) as genobj:
    for document in genobj:
        ...
</pre>
<p>This gets even worse if we consider the idiom of decomposing a complex
pipeline into multiple nested generators:</p>
<pre class="literal-block">
def read_users(path):
    with closing(read_newline_separated_json(path)) as gen:
        for document in gen:
            yield User.from_json(document)

def users_in_group(path, group):
    with closing(read_users(path)) as gen:
        for user in gen:
            if user.group == group:
                yield user
</pre>
<p>In general if you have N nested generators then you need N+1 <tt class="docutils literal">with</tt>
blocks to clean up 1 file. And good defensive programming would
suggest that any time we use a generator, we should assume the
possibility that there could be at least one <tt class="docutils literal">with</tt> block somewhere
in its (potentially transitive) call stack, either now or in the
future, and thus always wrap it in a <tt class="docutils literal">with</tt>. But in practice,
basically nobody does this, because programmers would rather write
buggy code than tiresome repetitive code. In simple cases like this
there are some workarounds that good Python developers know (e.g. in
this simple case it would be idiomatic to pass in a file handle
instead of a path and move the resource management to the top level),
but in general we cannot avoid the use of <tt class="docutils literal">with</tt>/<tt class="docutils literal">finally</tt> inside
of generators, and thus dealing with this problem one way or
another. When beauty and correctness fight then beauty tends to win,
so it's important to make correct code beautiful.</p>
<p>Still, is this worth fixing? Until async generators came along I would
have argued yes, but that it was a low priority, since everyone seems
to be muddling along okay -- but async generators make it much more
urgent. Async generators cannot do cleanup <em>at all</em> without some
mechanism for deterministic cleanup that people will actually use, and
async generators are particularly likely to hold resources like file
descriptors. (After all, if they weren't doing I/O, they'd be
generators, not async generators.) So we have to do something, and it
might as well be a comprehensive fix to the underlying problem. And
it's much easier to fix this now when async generators are first
rolling out, then it will be to fix it later.</p>
<p>The proposal itself is simple in concept: add a <tt class="docutils literal">__(a)iterclose__</tt>
method to the iterator protocol, and have (async) <tt class="docutils literal">for</tt> loops call
it when the loop is exited, even if this occurs via <tt class="docutils literal">break</tt> or
exception unwinding. Effectively, we're taking the current cumbersome
idiom (<tt class="docutils literal">with</tt> block + <tt class="docutils literal">for</tt> loop) and merging them together into a
fancier <tt class="docutils literal">for</tt>. This may seem non-orthogonal, but makes sense when
you consider that the existence of generators means that <tt class="docutils literal">with</tt>
blocks actually depend on iterator cleanup to work reliably, plus
experience showing that iterator cleanup is often a desireable feature
in its own right.</p>
</div>
<div class="section" id="alternatives">
<h1><a class="toc-backref" href="#id5">Alternatives</a></h1>
<div class="section" id="pep-525-asyncgen-hooks">
<h2><a class="reference external" href="/dev/peps/pep-0525">PEP 525</a> asyncgen hooks</h2>
<p><a class="reference external" href="/dev/peps/pep-0525">PEP 525</a> proposes a <cite>set of global thread-local hooks managed by new
``sys.{get/set}_asyncgen_hooks()`</cite> functions
&lt;<a class="reference external" href="https://www.python.org/dev/peps/pep-0525/#finalization">https://www.python.org/dev/peps/pep-0525/#finalization</a>&gt;`_, which
allow event loops to integrate with the garbage collector to run
cleanup for async generators. In principle, this proposal and <a class="reference external" href="/dev/peps/pep-0525">PEP 525</a>
are complementary, in the same way that <tt class="docutils literal">with</tt> blocks and
<tt class="docutils literal">__del__</tt> are complementary: this proposal takes care of ensuring
deterministic cleanup in most cases, while <a class="reference external" href="/dev/peps/pep-0525">PEP 525</a>'s GC hooks clean up
anything that gets missed. But <tt class="docutils literal">__aiterclose__</tt> provides a number of
advantages over GC hooks alone:</p>
<ul>
<li><p class="first">The GC hook semantics aren't part of the abstract async iterator
protocol, but are instead restricted <a class="reference external" href="https://mail.python.org/pipermail/python-dev/2016-September/146129.html">specifically to the async
generator concrete type</a>. If
you have an async iterator implemented using a class, like:</p>
<pre class="literal-block">
class MyAsyncIterator:
    async def __anext__():
        ...
</pre>
<p>then you can't refactor this into an async generator without
changing its semantics, and vice-versa. This seems very
unpythonic. (It also leaves open the question of what exactly
class-based async iterators are supposed to do, given that they face
exactly the same cleanup problems as async generators.)
<tt class="docutils literal">__aiterclose__</tt>, on the other hand, is defined at the protocol
level, so it's duck-type friendly and works for all iterators, not
just generators.</p>
</li>
<li><p class="first">Code that wants to work on non-CPython implementations like PyPy
cannot in general rely on GC for cleanup. Without
<tt class="docutils literal">__aiterclose__</tt>, it's more or less guaranteed that developers who
develop and test on CPython will produce libraries that leak
resources when used on PyPy. Developers who do want to target
alternative implementations will either have to take the defensive
approach of wrapping every <tt class="docutils literal">for</tt> loop in a <tt class="docutils literal">with</tt> block, or else
carefully audit their code to figure out which generators might
possibly contain cleanup code and add <tt class="docutils literal">with</tt> blocks around those
only. With <tt class="docutils literal">__aiterclose__</tt>, writing portable code becomes easy
and natural.</p>
</li>
<li><p class="first">An important part of building robust software is making sure that
exceptions always propagate correctly without being lost. One of the
most exciting things about async/await compared to traditional
callback-based systems is that instead of requiring manual chaining,
the runtime can now do the heavy lifting of propagating errors,
making it <em>much</em> easier to write robust code. But, this beautiful
new picture has one major gap: if we rely on the GC for generator
cleanup, then exceptions raised during cleanup are lost. So, again,
with <tt class="docutils literal">__aiterclose__</tt>, developers who care about this kind of
robustness will either have to take the defensive approach of
wrapping every <tt class="docutils literal">for</tt> loop in a <tt class="docutils literal">with</tt> block, or else carefully
audit their code to figure out which generators might possibly
contain cleanup code. <tt class="docutils literal">__aiterclose__</tt> plugs this hole by
performing cleanup in the caller's context, so writing more robust
code becomes the path of least resistance.</p>
</li>
<li><p class="first">The WSGI experience suggests that there exist important
iterator-based APIs that need prompt cleanup and cannot rely on the
GC, even in CPython. For example, consider a hypothetical WSGI-like
API based around async/await and async iterators, where a response
handler is an async generator that takes request headers + an async
iterator over the request body, and yields response headers + the
response body. (This is actually the use case that got me interested
in async generators in the first place, i.e. this isn't
hypothetical.) If we follow WSGI in requiring that child iterators
must be closed properly, then without <tt class="docutils literal">__aiterclose__</tt> the
absolute most minimalistic middleware in our system looks something
like:</p>
<pre class="literal-block">
async def noop_middleware(handler, request_header, request_body):
    async with aclosing(handler(request_body, request_body)) as aiter:
        async for response_item in aiter:
            yield response_item
</pre>
<p>Arguably in regular code one can get away with skipping the <tt class="docutils literal">with</tt>
block around <tt class="docutils literal">for</tt> loops, depending on how confident one is that
one understands the internal implementation of the generator. But
here we have to cope with arbitrary response handlers, so without
<tt class="docutils literal">__aiterclose__</tt>, this <tt class="docutils literal">with</tt> construction is a mandatory part
of every middleware.</p>
<p><tt class="docutils literal">__aiterclose__</tt> allows us to eliminate the mandatory boilerplate
and an extra level of indentation from every middleware:</p>
<pre class="literal-block">
async def noop_middleware(handler, request_header, request_body):
    async for response_item in handler(request_header, request_body):
        yield response_item
</pre>
</li>
</ul>
<p>So the <tt class="docutils literal">__aiterclose__</tt> approach provides substantial advantages
over GC hooks.</p>
<p>This leaves open the question of whether we want a combination of GC
hooks + <tt class="docutils literal">__aiterclose__</tt>, or just <tt class="docutils literal">__aiterclose__</tt> alone. Since
the vast majority of generators are iterated over using a <tt class="docutils literal">for</tt> loop
or equivalent, <tt class="docutils literal">__aiterclose__</tt> handles most situations before the
GC has a chance to get involved. The case where GC hooks provide
additional value is in code that does manual iteration, e.g.:</p>
<pre class="literal-block">
agen = fetch_newline_separated_json_from_url(...)
while True:
    document = await type(agen).__anext__(agen)
    if document[&quot;id&quot;] == needle:
        break
# doesn't do 'await agen.aclose()'
</pre>
<p>If we go with the GC-hooks + <tt class="docutils literal">__aiterclose__</tt> approach, this
generator will eventually be cleaned up by GC calling the generator
<tt class="docutils literal">__del__</tt> method, which then will use the hooks to call back into
the event loop to run the cleanup code.</p>
<p>If we go with the no-GC-hooks approach, this generator will eventually
be garbage collected, with the following effects:</p>
<ul class="simple">
<li>its <tt class="docutils literal">__del__</tt> method will issue a warning that the generator was
not closed (similar to the existing &quot;coroutine never awaited&quot;
warning).</li>
<li>The underlying resources involved will still be cleaned up, because
the generator frame will still be garbage collected, causing it to
drop references to any file handles or sockets it holds, and then
those objects's <tt class="docutils literal">__del__</tt> methods will release the actual
operating system resources.</li>
<li>But, any cleanup code inside the generator itself (e.g. logging,
buffer flushing) will not get a chance to run.</li>
</ul>
<p>The solution here -- as the warning would indicate -- is to fix the
code so that it calls <tt class="docutils literal">__aiterclose__</tt>, e.g. by using a <tt class="docutils literal">with</tt>
block:</p>
<pre class="literal-block">
async with aclosing(fetch_newline_separated_json_from_url(...)) as agen:
    while True:
        document = await type(agen).__anext__(agen)
        if document[&quot;id&quot;] == needle:
            break
</pre>
<p>Basically in this approach, the rule would be that if you want to
manually implement the iterator protocol, then it's your
responsibility to implement all of it, and that now includes
<tt class="docutils literal">__(a)iterclose__</tt>.</p>
<p>GC hooks add non-trivial complexity in the form of (a) new global
interpreter state, (b) a somewhat complicated control flow (e.g.,
async generator GC always involves resurrection, so the details of <a class="reference external" href="/dev/peps/pep-0442">PEP
442</a> are important), and (c) a new public API in asyncio (<tt class="docutils literal">await
loop.shutdown_asyncgens()</tt>) that users have to remember to call at
the appropriate time. (This last point in particular somewhat
undermines the argument that GC hooks provide a safe backup to
guarantee cleanup, since if <tt class="docutils literal">shutdown_asyncgens()</tt> isn't called
correctly then I <em>think</em> it's possible for generators to be silently
discarded without their cleanup code being called; compare this to the
<tt class="docutils literal">__aiterclose__</tt>-only approach where in the worst case we still at
least get a warning printed. This might be fixable.) All this
considered, GC hooks arguably aren't worth it, given that the only
people they help are those who want to manually call <tt class="docutils literal">__anext__</tt> yet
don't want to manually call <tt class="docutils literal">__aiterclose__</tt>. But Yury disagrees
with me on this :-). And both options are viable.</p>
</div>
<div class="section" id="always-inject-resources-and-do-all-cleanup-at-the-top-level">
<h2><a class="toc-backref" href="#id7">Always inject resources, and do all cleanup at the top level</a></h2>
<p>Several commentators on python-dev and python-ideas have suggested
that a pattern to avoid these problems is to always pass resources in
from above, e.g. <tt class="docutils literal">read_newline_separated_json</tt> should take a file
object rather than a path, with cleanup handled at the top level:</p>
<pre class="literal-block">
def read_newline_separated_json(file_handle):
    for line in file_handle:
        yield json.loads(line)

def read_users(file_handle):
    for document in read_newline_separated_json(file_handle):
        yield User.from_json(document)

with open(path) as file_handle:
    for user in read_users(file_handle):
        ...
</pre>
<p>This works well in simple cases; here it lets us avoid the &quot;N+1
<tt class="docutils literal">with</tt> blocks problem&quot;. But unfortunately, it breaks down quickly
when things get more complex. Consider if instead of reading from a
file, our generator was reading from a streaming HTTP GET request --
while handling redirects and authentication via OAUTH. Then we'd
really want the sockets to be managed down inside our HTTP client
library, not at the top level. Plus there are other cases where
<tt class="docutils literal">finally</tt> blocks embedded inside generators are important in their
own right: db transaction management, emitting logging information
during cleanup (one of the major motivating use cases for WSGI
<tt class="docutils literal">close</tt>), and so forth. So this is really a workaround for simple
cases, not a general solution.</p>
</div>
<div class="section" id="more-complex-variants-of-a-iterclose">
<h2><a class="toc-backref" href="#id8">More complex variants of __(a)iterclose__</a></h2>
<p>The semantics of <tt class="docutils literal">__(a)iterclose__</tt> are somewhat inspired by
<tt class="docutils literal">with</tt> blocks, but context managers are more powerful:
<tt class="docutils literal">__(a)exit__</tt> can distinguish between a normal exit versus exception
unwinding, and in the case of an exception it can examine the
exception details and optionally suppress
propagation. <tt class="docutils literal">__(a)iterclose__</tt> as proposed here does not have these
powers, but one can imagine an alternative design where it did.</p>
<p>However, this seems like unwarranted complexity: experience suggests
that it's common for iterables to have <tt class="docutils literal">close</tt> methods, and even to
have <tt class="docutils literal">__exit__</tt> methods that call <tt class="docutils literal">self.close()</tt>, but I'm not
aware of any common cases that make use of <tt class="docutils literal">__exit__</tt>'s full
power. I also can't think of any examples where this would be
useful. And it seems unnecessarily confusing to allow iterators to
affect flow control by swallowing exceptions -- if you're in a
situation where you really want that, then you should probably use a
real <tt class="docutils literal">with</tt> block anyway.</p>
</div>
</div>
<div class="section" id="specification">
<h1><a class="toc-backref" href="#id9">Specification</a></h1>
<p>This section describes where we want to eventually end up, though
there are some backwards compatibility issues that mean we can't jump
directly here. A later section describes the transition plan.</p>
<div class="section" id="guiding-principles">
<h2><a class="toc-backref" href="#id10">Guiding principles</a></h2>
<p>Generally, <tt class="docutils literal">__(a)iterclose__</tt> implementations should:</p>
<ul class="simple">
<li>be idempotent,</li>
<li>perform any cleanup that is appropriate on the assumption that the
iterator will not be used again after <tt class="docutils literal">__(a)iterclose__</tt> is
called. In particular, once <tt class="docutils literal">__(a)iterclose__</tt> has been called
then calling <tt class="docutils literal">__(a)next__</tt> produces undefined behavior.</li>
</ul>
<p>And generally, any code which starts iterating through an iterable
with the intention of exhausting it, should arrange to make sure that
<tt class="docutils literal">__(a)iterclose__</tt> is eventually called, whether or not the iterator
is actually exhausted.</p>
</div>
<div class="section" id="changes-to-iteration">
<h2><a class="toc-backref" href="#id11">Changes to iteration</a></h2>
<p>The core proposal is the change in behavior of <tt class="docutils literal">for</tt> loops. Given
this Python code:</p>
<pre class="literal-block">
for VAR in ITERABLE:
    LOOP-BODY
else:
    ELSE-BODY
</pre>
<p>we desugar to the equivalent of:</p>
<pre class="literal-block">
_iter = iter(ITERABLE)
_iterclose = getattr(type(_iter), &quot;__iterclose__&quot;, lambda: None)
try:
    traditional-for VAR in _iter:
        LOOP-BODY
    else:
        ELSE-BODY
finally:
    _iterclose(_iter)
</pre>
<p>where the &quot;traditional-for statement&quot; here is meant as a shorthand for
the classic 3.5-and-earlier <tt class="docutils literal">for</tt> loop semantics.</p>
<p>Besides the top-level <tt class="docutils literal">for</tt> statement, Python also contains several
other places where iterators are consumed. For consistency, these
should call <tt class="docutils literal">__iterclose__</tt> as well using semantics equivalent to
the above. This includes:</p>
<ul class="simple">
<li><tt class="docutils literal">for</tt> loops inside comprehensions</li>
<li><tt class="docutils literal">*</tt> unpacking</li>
<li>functions which accept and fully consume iterables, like
<tt class="docutils literal">list(it)</tt>, <tt class="docutils literal">tuple(it)</tt>, <tt class="docutils literal">itertools.product(it1, it2, <span class="pre">...)</span></tt>,
and others.</li>
</ul>
<p>In addition, a <tt class="docutils literal">yield from</tt> that successfully exhausts the called
generator should as a last step call its <tt class="docutils literal">__iterclose__</tt>
method. (Rationale: <tt class="docutils literal">yield from</tt> already links the lifetime of the
calling generator to the called generator; if the calling generator is
closed when half-way through a <tt class="docutils literal">yield from</tt>, then this will already
automatically close the called generator.)</p>
</div>
<div class="section" id="changes-to-async-iteration">
<h2><a class="toc-backref" href="#id12">Changes to async iteration</a></h2>
<p>We also make the analogous changes to async iteration constructs,
except that the new slot is called <tt class="docutils literal">__aiterclose__</tt>, and it's an
async method that gets <tt class="docutils literal">await</tt>ed.</p>
</div>
<div class="section" id="modifications-to-basic-iterator-types">
<h2><a class="toc-backref" href="#id13">Modifications to basic iterator types</a></h2>
<p>Generator objects (including those created by generator
comprehensions):</p>
<ul class="simple">
<li><tt class="docutils literal">__iterclose__</tt> calls <tt class="docutils literal">self.close()</tt></li>
<li><tt class="docutils literal">__del__</tt> calls <tt class="docutils literal">self.close()</tt> (same as now), and additionally
issues a <tt class="docutils literal">ResourceWarning</tt> if the generator wasn't exhausted. This
warning is hidden by default, but can be enabled for those who want
to make sure they aren't inadverdantly relying on CPython-specific
GC semantics.</li>
</ul>
<p>Async generator objects (including those created by async generator
comprehensions):</p>
<ul class="simple">
<li><tt class="docutils literal">__aiterclose__</tt> calls <tt class="docutils literal">self.aclose()</tt></li>
<li><tt class="docutils literal">__del__</tt> issues a <tt class="docutils literal">RuntimeWarning</tt> if <tt class="docutils literal">aclose</tt> has not been
called, since this probably indicates a latent bug, similar to the
&quot;coroutine never awaited&quot; warning.</li>
</ul>
<p>QUESTION: should file objects implement <tt class="docutils literal">__iterclose__</tt> to close the
file? On the one hand this would make this change more disruptive; on
the other hand people really like writing <tt class="docutils literal">for line in <span class="pre">open(...):</span>
...</tt>, and if we get used to iterators taking care of their own
cleanup then it might become very weird if files don't.</p>
</div>
<div class="section" id="new-convenience-functions">
<h2><a class="toc-backref" href="#id14">New convenience functions</a></h2>
<p>The <tt class="docutils literal">operator</tt> module gains two new functions, with semantics
equivalent to the following:</p>
<pre class="literal-block">
def iterclose(it):
    if not isinstance(it, collections.abc.Iterator):
        raise TypeError(&quot;not an iterator&quot;)
    if hasattr(type(it), &quot;__iterclose__&quot;):
        type(it).__iterclose__(it)

async def aiterclose(ait):
    if not isinstance(it, collections.abc.AsyncIterator):
        raise TypeError(&quot;not an iterator&quot;)
    if hasattr(type(ait), &quot;__aiterclose__&quot;):
        await type(ait).__aiterclose__(ait)
</pre>
<p>The <tt class="docutils literal">itertools</tt> module gains a new iterator wrapper that can be used
to selectively disable the new <tt class="docutils literal">__iterclose__</tt> behavior:</p>
<pre class="literal-block">
# QUESTION: I feel like there might be a better name for this one?
class preserve(iterable):
    def __init__(self, iterable):
        self._it = iter(iterable)

    def __iter__(self):
        return self

    def __next__(self):
        return next(self._it)

    def __iterclose__(self):
        # Swallow __iterclose__ without passing it on
        pass
</pre>
<p>Example usage (assuming that file objects implements
<tt class="docutils literal">__iterclose__</tt>):</p>
<pre class="literal-block">
with open(...) as handle:
    # Iterate through the same file twice:
    for line in itertools.preserve(handle):
        ...
    handle.seek(0)
    for line in itertools.preserve(handle):
        ...
</pre>
<pre class="literal-block">
&#64;contextlib.contextmanager
def iterclosing(iterable):
    it = iter(iterable)
    try:
        yield preserve(it)
    finally:
        iterclose(it)
</pre>
</div>
<div class="section" id="iterclose-implementations-for-iterator-wrappers">
<h2><a class="toc-backref" href="#id15">__iterclose__ implementations for iterator wrappers</a></h2>
<p>Python ships a number of iterator types that act as wrappers around
other iterators: <tt class="docutils literal">map</tt>, <tt class="docutils literal">zip</tt>, <tt class="docutils literal">itertools.accumulate</tt>,
<tt class="docutils literal">csv.reader</tt>, and others. These iterators should define a
<tt class="docutils literal">__iterclose__</tt> method which calls <tt class="docutils literal">__iterclose__</tt> in turn on
their underlying iterators. For example, <tt class="docutils literal">map</tt> could be implemented
as:</p>
<pre class="literal-block">
# Helper function
map_chaining_exceptions(fn, items, last_exc=None):
    for item in items:
        try:
            fn(item)
        except BaseException as new_exc:
            if new_exc.__context__ is None:
                new_exc.__context__ = last_exc
            last_exc = new_exc
    if last_exc is not None:
        raise last_exc

class map:
    def __init__(self, fn, *iterables):
        self._fn = fn
        self._iters = [iter(iterable) for iterable in iterables]

    def __iter__(self):
        return self

    def __next__(self):
        return self._fn(*[next(it) for it in self._iters])

    def __iterclose__(self):
        map_chaining_exceptions(operator.iterclose, self._iters)

def chain(*iterables):
    try:
        while iterables:
            for element in iterables.pop(0):
                yield element
    except BaseException as e:
        def iterclose_iterable(iterable):
            operations.iterclose(iter(iterable))
        map_chaining_exceptions(iterclose_iterable, iterables, last_exc=e)
</pre>
<p>In some cases this requires some subtlety; for example,
<tt class="docutils literal">`itertools.tee</tt>
&lt;<a class="reference external" href="https://docs.python.org/3/library/itertools.html#itertools.tee">https://docs.python.org/3/library/itertools.html#itertools.tee</a>&gt;`_
should not call <tt class="docutils literal">__iterclose__</tt> on the underlying iterator until it
has been called on <em>all</em> of the clone iterators.</p>
</div>
<div class="section" id="example-rationale">
<h2><a class="toc-backref" href="#id16">Example / Rationale</a></h2>
<p>The payoff for all this is that we can now write straightforward code
like:</p>
<pre class="literal-block">
def read_newline_separated_json(path):
    for line in open(path):
        yield json.loads(line)
</pre>
<p>and be confident that the file will receive deterministic cleanup
<em>without the end-user having to take any special effort</em>, even in
complex cases. For example, consider this silly pipeline:</p>
<pre class="literal-block">
list(map(lambda key: key.upper(),
         doc[&quot;key&quot;] for doc in read_newline_separated_json(path)))
</pre>
<p>If our file contains a document where <tt class="docutils literal"><span class="pre">doc[&quot;key&quot;]</span></tt> turns out to be
an integer, then the following sequence of events will happen:</p>
<ol class="arabic simple">
<li><tt class="docutils literal">key.upper()</tt> raises an <tt class="docutils literal">AttributeError</tt>, which propagates out
of the <tt class="docutils literal">map</tt> and triggers the implicit <tt class="docutils literal">finally</tt> block inside
<tt class="docutils literal">list</tt>.</li>
<li>The <tt class="docutils literal">finally</tt> block in <tt class="docutils literal">list</tt> calls <tt class="docutils literal">__iterclose__()</tt> on the
map object.</li>
<li><tt class="docutils literal">map.__iterclose__()</tt> calls <tt class="docutils literal">__iterclose__()</tt> on the generator
comprehension object.</li>
<li>This injects a <tt class="docutils literal">GeneratorExit</tt> exception into the generator
comprehension body, which is currently suspended inside the
comprehension's <tt class="docutils literal">for</tt> loop body.</li>
<li>The exception propagates out of the <tt class="docutils literal">for</tt> loop, triggering the
<tt class="docutils literal">for</tt> loop's implicit <tt class="docutils literal">finally</tt> block, which calls
<tt class="docutils literal">__iterclose__</tt> on the generator object representing the call to
<tt class="docutils literal">read_newline_separated_json</tt>.</li>
<li>This injects an inner <tt class="docutils literal">GeneratorExit</tt> exception into the body of
<tt class="docutils literal">read_newline_separated_json</tt>, currently suspended at the
<tt class="docutils literal">yield</tt>.</li>
<li>The inner <tt class="docutils literal">GeneratorExit</tt> propagates out of the <tt class="docutils literal">for</tt> loop,
triggering the <tt class="docutils literal">for</tt> loop's implicit <tt class="docutils literal">finally</tt> block, which
calls <tt class="docutils literal">__iterclose__()</tt> on the file object.</li>
<li>The file object is closed.</li>
<li>The inner <tt class="docutils literal">GeneratorExit</tt> resumes propagating, hits the boundary
of the generator function, and causes
<tt class="docutils literal">read_newline_separated_json</tt>'s <tt class="docutils literal">__iterclose__()</tt> method to
return successfully.</li>
<li>Control returns to the generator comprehension body, and the outer
<tt class="docutils literal">GeneratorExit</tt> continues propagating, allowing the
comprehension's <tt class="docutils literal">__iterclose__()</tt> to return successfully.</li>
<li>The rest of the <tt class="docutils literal">__iterclose__()</tt> calls unwind without incident,
back into the body of <tt class="docutils literal">list</tt>.</li>
<li>The original <tt class="docutils literal">AttributeError</tt> resumes propagating.</li>
</ol>
<p>(The details above assume that we implement <tt class="docutils literal">file.__iterclose__</tt>; if
not then add a <tt class="docutils literal">with</tt> block to <tt class="docutils literal">read_newline_separated_json</tt> and
essentially the same logic goes through.)</p>
<p>Of course, from the user's point of view, this can be simplified down
to just:</p>
<p>1. <tt class="docutils literal">int.upper()</tt> raises an <tt class="docutils literal">AttributeError</tt>
1. The file object is closed.
2. The <tt class="docutils literal">AttributeError</tt> propagates out of <tt class="docutils literal">list</tt></p>
<p>So we've accomplished our goal of making this &quot;just work&quot; without the
user having to think about it.</p>
</div>
</div>
<div class="section" id="transition-plan">
<h1><a class="toc-backref" href="#id17">Transition plan</a></h1>
<p>While the majority of existing <tt class="docutils literal">for</tt> loops will continue to produce
identical results, the proposed changes will produce
backwards-incompatible behavior in some cases. Example:</p>
<pre class="literal-block">
def read_csv_with_header(lines_iterable):
    lines_iterator = iter(lines_iterable)
    for line in lines_iterator:
        column_names = line.strip().split(&quot;\t&quot;)
        break
    for line in lines_iterator:
        values = line.strip().split(&quot;\t&quot;)
        record = dict(zip(column_names, values))
        yield record
</pre>
<p>This code used to be correct, but after this proposal is implemented
will require an <tt class="docutils literal">itertools.preserve</tt> call added to the first <tt class="docutils literal">for</tt>
loop.</p>
<p>[QUESTION: currently, if you close a generator and then try to iterate
over it then it just raises <tt class="docutils literal">Stop(Async)Iteration</tt>, so code the
passes the same generator object to multiple <tt class="docutils literal">for</tt> loops but forgets
to use <tt class="docutils literal">itertools.preserve</tt> won't see an obvious error -- the second
<tt class="docutils literal">for</tt> loop will just exit immediately. Perhaps it would be better if
iterating a closed generator raised a <tt class="docutils literal">RuntimeError</tt>? Note that
files don't have this problem -- attempting to iterate a closed file
object already raises <tt class="docutils literal">ValueError</tt>.]</p>
<p>Specifically, the incompatibility happens when all of these factors
come together:</p>
<ul class="simple">
<li>The automatic calling of <tt class="docutils literal">__(a)iterclose__</tt> is enabled</li>
<li>The iterable did not previously define <tt class="docutils literal">__(a)iterclose__</tt></li>
<li>The iterable does now define <tt class="docutils literal">__(a)iterclose__</tt></li>
<li>The iterable is re-used after the <tt class="docutils literal">for</tt> loop exits</li>
</ul>
<p>So the problem is how to manage this transition, and those are the
levers we have to work with.</p>
<p>First, observe that the only async iterables where we propose to add
<tt class="docutils literal">__aiterclose__</tt> are async generators, and there is currently no
existing code using async generators (though this will start changing
very soon), so the async changes do not produce any backwards
incompatibilities. (There is existing code using async iterators, but
using the new async for loop on an old async iterator is harmless,
because old async iterators don't have <tt class="docutils literal">__aiterclose__</tt>.) In
addition, <a class="reference external" href="/dev/peps/pep-0525">PEP 525</a> was accepted on a provisional basis, and async
generators are by far the biggest beneficiary of this PEP's proposed
changes. Therefore, I think we should strongly consider enabling
<tt class="docutils literal">__aiterclose__</tt> for <tt class="docutils literal">async for</tt> loops and async generators ASAP,
ideally for 3.6.0 or 3.6.1.</p>
<p>For the non-async world, things are harder, but here's a potential
transition path:</p>
<p>In 3.7:</p>
<p>Our goal is that existing unsafe code will start emitting warnings,
while those who want to opt-in to the future can do that immediately:</p>
<ul class="simple">
<li>We immediately add all the <tt class="docutils literal">__iterclose__</tt> methods described
above.</li>
<li>If <tt class="docutils literal">from __future__ import iterclose</tt> is in effect, then <tt class="docutils literal">for</tt>
loops and <tt class="docutils literal">*</tt> unpacking call <tt class="docutils literal">__iterclose__</tt> as specified above.</li>
<li>If the future is <em>not</em> enabled, then <tt class="docutils literal">for</tt> loops and <tt class="docutils literal">*</tt>
unpacking do <em>not</em> call <tt class="docutils literal">__iterclose__</tt>. But they do call some
other method instead, e.g. <tt class="docutils literal">__iterclose_warning__</tt>.</li>
<li>Similarly, functions like <tt class="docutils literal">list</tt> use stack introspection (!!) to
check whether their direct caller has <tt class="docutils literal">__future__.iterclose</tt>
enabled, and use this to decide whether to call <tt class="docutils literal">__iterclose__</tt> or
<tt class="docutils literal">__iterclose_warning__</tt>.</li>
<li>For all the wrapper iterators, we also add <tt class="docutils literal">__iterclose_warning__</tt>
methods that forward to the <tt class="docutils literal">__iterclose_warning__</tt> method of the
underlying iterator or iterators.</li>
<li>For generators (and files, if we decide to do that),
<tt class="docutils literal">__iterclose_warning__</tt> is defined to set an internal flag, and
other methods on the object are modified to check for this flag. If
they find the flag set, they issue a <tt class="docutils literal">PendingDeprecationWarning</tt>
to inform the user that in the future this sequence would have led
to a use-after-close situation and the user should use
<tt class="docutils literal">preserve()</tt>.</li>
</ul>
<p>In 3.8:</p>
<ul class="simple">
<li>Switch from <tt class="docutils literal">PendingDeprecationWarning</tt> to <tt class="docutils literal">DeprecationWarning</tt></li>
</ul>
<p>In 3.9:</p>
<ul class="simple">
<li>Enable the <tt class="docutils literal">__future__</tt> unconditionally and remove all the
<tt class="docutils literal">__iterclose_warning__</tt> stuff.</li>
</ul>
<p>I believe that this satisfies the normal requirements for this kind of
transition -- opt-in initially, with warnings targeted precisely to
the cases that will be effected, and a long deprecation cycle.</p>
<p>Probably the most controversial / risky part of this is the use of
stack introspection to make the iterable-consuming functions sensitive
to a <tt class="docutils literal">__future__</tt> setting, though I haven't thought of any situation
where it would actually go wrong yet...</p>
</div>
<div class="section" id="acknowledgements">
<h1><a class="toc-backref" href="#id18">Acknowledgements</a></h1>
<p>Thanks to Yury Selivanov, Armin Rigo, and Carl Friedrich Bolz for
helpful discussion on earlier versions of this idea.</p>
</div>
<div class="section" id="copyright">
<h1><a class="toc-backref" href="#id19">Copyright</a></h1>
<p>This document has been placed in the public domain.</p>
</div>

